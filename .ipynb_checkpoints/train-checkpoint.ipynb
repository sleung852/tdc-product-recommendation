{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model.gmf import GMFEngine\n",
    "from model.mlp import MLPEngine\n",
    "from model.neumf import NeuMFEngine\n",
    "from data import SampleGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleaned_data.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_dir = 'data/cleaned_data.csv'\n",
    "tdc_record = pd.read_csv(data_dir, names=['uid', 'mid', 'timestamp'],  engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of userId is [0, 11410]\n",
      "Range of itemId is [0, 13202]\n",
      "userId         int32\n",
      "itemId         int32\n",
      "rating         int32\n",
      "timestamp    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Reindex\n",
    "tdc_record = tdc_record.iloc[1:,:]\n",
    "user_id = tdc_record[['uid']].drop_duplicates().reindex()\n",
    "user_id['userId'] = np.arange(len(user_id))\n",
    "tdc_record = pd.merge(tdc_record, user_id, on=['uid'], how='left')\n",
    "item_id = tdc_record[['mid']].drop_duplicates()\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "tdc_record = pd.merge(tdc_record, item_id, on=['mid'], how='left')\n",
    "tdc_record['rating']=1.0\n",
    "tdc_record = tdc_record[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "\n",
    "tdc_record['rating']=tdc_record['rating'].astype('int32')\n",
    "tdc_record['timestamp']=tdc_record['timestamp'].astype('float64')\n",
    "\n",
    "print('Range of userId is [{}, {}]'.format(tdc_record.userId.min(), tdc_record.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(tdc_record.itemId.min(), tdc_record.itemId.max()))\n",
    "print(tdc_record.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_itemid=len(tdc_record['itemId'].unique())\n",
    "\n",
    "num_userid=len(tdc_record['userId'].unique())\n",
    "\n",
    "tdc_record.drop_duplicates(inplace=True)\n",
    "\n",
    "# tdc_record.groupby('userId').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No useless data\n"
     ]
    }
   ],
   "source": [
    "#print double check any useless items\n",
    "\n",
    "df=tdc_record.groupby('userId').count()\n",
    "\n",
    "user_id_drop= df[df['itemId']==1].index\n",
    "\n",
    "drop_index=[]\n",
    "for ind, row in tdc_record.iterrows():\n",
    "    if row['userId'] in user_id_drop:\n",
    "        drop_index.append(ind)\n",
    "\n",
    "if len(drop_index)==0:\n",
    "    print('No useless data')\n",
    "else:\n",
    "    print('found {} useless datapoints'.format(len(drop_index)))\n",
    "    tdc_record.drop(drop_index, inplace=True)\n",
    "    print('data cleaned!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "begin preprocess_ratings\n",
      "begin setting pools\n",
      "creating negative items\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11411/11411 [00:03<00:00, 2975.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11411/11411 [00:02<00:00, 4649.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_loo\n",
      "Done!\n",
      "Begin the loop...\n"
     ]
    }
   ],
   "source": [
    "# DataLoader for training\n",
    "sample_generator = SampleGenerator(ratings=tdc_record)\n",
    "evaluate_data = sample_generator.evaluate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Engine\n",
    "def train_model(model, config):\n",
    "    engine = model(config)\n",
    "    best_hit = 0\n",
    "    for epoch in range(config['num_epoch']):\n",
    "        print('Epoch {} starts !'.format(epoch))\n",
    "        print('-' * 70)\n",
    "        train_loader = sample_generator.instance_a_train_loader(config['num_negative'], config['batch_size'])\n",
    "        engine.train_an_epoch(train_loader, epoch_id=epoch)\n",
    "        hit_ratio, ndcg = engine.evaluate(evaluate_data, epoch_id=epoch)\n",
    "        if epoch % 20 == 0:\n",
    "            engine.save(config['alias'], epoch, hit_ratio, ndcg)\n",
    "        elif (epoch == config['num_epoch'] - 1):\n",
    "            engine.save(config['alias'], epoch, hit_ratio, ndcg)\n",
    "        if hit_ratio > best_hit:\n",
    "            best_hit = hit_ratio\n",
    "            engine.save(config['alias'], epoch, hit_ratio, ndcg, backup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup configuration for GMF\n",
    "gmf_config = {'alias': 'gmf_factor8neg4-implict',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 4,\n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "              # 'optimizer': 'rmsprop',\n",
    "              # 'rmsprop_lr': 1e-3,\n",
    "              # 'rmsprop_alpha': 0.99,\n",
    "              # 'rmsprop_momentum': 0,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': num_userid,\n",
    "              'num_items': num_itemid,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'l2_regularization': 0, # 0.01\n",
    "              'use_cuda': True,\n",
    "              'device_id': 0,\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12%5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "[Training Stage Epoch 0] Loss 0.5723008513450623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\tdc-product-recommendation\\metrics.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  test_in_top_k['ndcg'] = test_in_top_k['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluating Epoch 0] HR = 0.0970, NDCG = 0.0436\n",
      "Epoch 1 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "[Training Stage Epoch 1] Loss 0.925452709197998\n",
      "Epoch 2 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "[Training Stage Epoch 2] Loss 0.5774462223052979\n",
      "Epoch 3 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "[Training Stage Epoch 3] Loss 0.2143295854330063\n",
      "Epoch 4 starts !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train GMF Model\n",
    "train_model(GMFEngine, gmf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find file name\n",
    "gmf_model='tbc'\n",
    "for file in os.listdir('checkpoints/'):\n",
    "    leng= len('gmf_factor8neg4-implict_Epoch199')\n",
    "    if file[:leng]=='gmf_factor8neg4-implict_Epoch199':\n",
    "        print (file)\n",
    "        gmf_model=file\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 4,  # 1024,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': num_userid,\n",
    "              'num_items': num_itemid,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "              'use_cuda': True,\n",
    "              'device_id': 0,\n",
    "              'pretrain': True,\n",
    "              'pretrain_mf': os.path.join('checkpoints',gmf_model),\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model(MLPEngine, mlp_config)\n",
    "#need to add a learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model='tbc'\n",
    "for file in os.listdir('checkpoints/'):\n",
    "    leng= len('mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001_Epoch199')\n",
    "    if file[:leng]=='mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001_Epoch199':\n",
    "        print (file)\n",
    "        mlp_model=file\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 200,\n",
    "                'batch_size': 4,\n",
    "                'optimizer': 'adam',\n",
    "                'adam_lr': 1e-3,\n",
    "                'num_users': num_userid,\n",
    "              'num_items': num_itemid,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'num_negative': 4,\n",
    "                'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'l2_regularization': 0.0000001,\n",
    "                'use_cuda': True,\n",
    "                'device_id': 0,\n",
    "                'pretrain': True,\n",
    "                'pretrain_mf': 'checkpoints/{}'.format(gmf_model),\n",
    "                'pretrain_mlp': 'checkpoints/{}'.format(mlp_model),\n",
    "                'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(NeuMFEngine, neumf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in os.listdir('checkpoints'):\n",
    "#    os.remove(os.path.join('checkpoints', item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in os.listdir('checkpoints'):\n",
    "#    if item[:3]=='pre':\n",
    "#        os.remove(os.path.join('checkpoints', item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
